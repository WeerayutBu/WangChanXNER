{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fame/anaconda3/envs/wangchanxner/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "import torch\n",
    "from utils.utils import predict, show\n",
    "\n",
    "## check cuda availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: logging configuration file is not found in logger/logger_config.json.\n",
      "Train : 10409 sentences\n",
      "Dev : 3486 sentences\n",
      "Test : 3442 sentences\n",
      "Max sents length: 512 tokens\n",
      "num_vocab: 250002\n",
      "num_tag: 105\n",
      "num_span: 5\n",
      "num_spantag: 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np \n",
    "\n",
    "import model.model as module_arch\n",
    "import utils.dataloader as module_data\n",
    "\n",
    "from utils.metric import evaluate \n",
    "from utils.utils import decode_tags\n",
    "from utils.metric import sequence_f1\n",
    "from utils.parse_config import ConfigParser\n",
    "\n",
    "resume = 'storage/best_model/model_best.pth'\n",
    "\n",
    "args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)')\n",
    "args.add_argument('-r', '--resume', default=f\"{resume}\", type=str, help='path to latest checkpoint (default: None)')\n",
    "args.add_argument('-d', '--device', default='cpu', type=str, help='indices of GPUs to enable (default: all)')\n",
    "args.add_argument('--f', default='save', type=None)\n",
    "\n",
    "# Check if in IPython environment\n",
    "if any(\"ipykernel\" in arg for arg in sys.argv):\n",
    "    sys.argv = sys.argv[:1]  # Keep only the script name\n",
    "    \n",
    "config = ConfigParser.from_args(args)\n",
    "logger = config.get_logger('test')\n",
    "\n",
    "# setup dataloader instances\n",
    "data_loader = config.init_obj('dataloader', module_data)\n",
    "\n",
    "# build model architecturea\n",
    "model = config.init_obj('arch', module_arch, num_tag=data_loader.num_tag, path_lm=data_loader.path_lm)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "metric_fns = {\"sequence_f1\": sequence_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:test:Loading checkpoint: storage/best_model/model_best.pth ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NERModel(\n",
       "  (lm): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): XLMRobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sequence_decoder): MLP(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=417, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
    "# checkpoint = torch.load(config.resume)\n",
    "# state_dict = checkpoint['state_dict']\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "## \n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "checkpoint = torch.load(config.resume, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>|เมื่อ|วันที่|29|ก|.|ค|.|55||สํานัก|ข่าว||บี|บี|ซี||รายงาน|ว่า|มหาวิทยาลัย||ออก|ซ์||ฟอร์ด|ของ||อังกฤษ|ได้||แก้ไข||กฎ|การ||แต่ง|กาย||ภายใน|มหาวิทยาลัย|หลัง||ชม|รม|เพื่อ|ความ|หลากหลาย|ทาง|เพศ||ยื่น|คํา|ร้อง|ว่า||กฎ|ที่|มี|อยู่||เดิม|ไม่|เป็น|ธรรม|กับ|กลุ่ม|น|ศ||ข้าม||เพศ|trans|gende|r|ใน|มหาวิทยาลัย|</s> \n",
      "\n",
      "[2, 9]         date           วันที่29ก.ค.55\n",
      "[12, 16]       media          บีบีซี\n",
      "[26, 28]       country        อังกฤษ\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import predict, show\n",
    "\n",
    "text = \"\"\"\n",
    "เมื่อวันที่29ก.ค.55 สำนักข่าวบีบีซีรายงานว่า มหาวิทยาลัยออกซ์ฟอร์ดของอังกฤษได้แก้ไขกฎการแต่งกายภายในมหาวิทยาลัย หลังชมรมเพื่อความหลากหลายทางเพศยื่นคำร้องว่ากฎที่มีอยู่เดิมไม่เป็นธรรมกับกลุ่มนศข้ามเพศtransgenderใน\n",
    "มหาวิทยาลัย\n",
    "\"\"\"\n",
    "# Setup\n",
    "lm_path = data_loader.path_lm\n",
    "ids2tag = data_loader.ids2spantag\n",
    "max_sent_length = data_loader.sent_length\n",
    "\n",
    "tokens, out = predict(model, text, lm_path, ids2tag, max_sent_length)\n",
    "tokens = [tk for tk in tokens if tk!=data_loader.pad]\n",
    "\n",
    "print(\"|\".join(tokens), \"\\n\")\n",
    "[show(x) for x in out];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
